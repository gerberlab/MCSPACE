{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aa2193e",
   "metadata": {},
   "source": [
    "# Tutorial 2: Running inference with the MCSPACE model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfb25d8",
   "metadata": {},
   "source": [
    "This tutorial goes over how to run model inference on processed SAMPL-seq data. Refer to the previous tutorial (`data_preprocessing.ipynb`) on how to prepare data for inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f49c0288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcspace.data_utils import parse\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from mcspace.utils import pickle_save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e11f758",
   "metadata": {},
   "source": [
    "The \"run_inference\" function performs model inference on preprocessed SAMPL-seq data. Import it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a5d75bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcspace.inference import run_inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379b5ea2",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4ce289",
   "metadata": {},
   "source": [
    "Relative paths for this tutorial. `basepath` gives the path of this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2020e645",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = Path(\"./\")\n",
    "datapath = basepath / \"data\"\n",
    "outpath = basepath / \"results\"\n",
    "outpath.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f7063f",
   "metadata": {},
   "source": [
    "# Process data for model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e885b4bf",
   "metadata": {},
   "source": [
    "See previous tutorial `data_preprocessing.ipynb` for more details on this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a0edbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_remove = [10,18,65,76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd5d10c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gary\\documents\\projects\\mcspace_final\\mcspace\\mcspace\\dataset.py:23: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self._long_data = pd.read_csv(reads, compression='gzip')\n"
     ]
    }
   ],
   "source": [
    "processed_data = parse(datapath/\"mouse_counts.csv.gz\",\n",
    "                     datapath/\"taxonomy.csv\",\n",
    "                     datapath/\"perturbations.csv\",\n",
    "                     subjects_remove=['JX09'],\n",
    "                     times_remove=times_remove,\n",
    "                     otus_remove=None,\n",
    "                     num_consistent_subjects=2,\n",
    "                     min_abundance=0.005,\n",
    "                     min_reads=1000,\n",
    "                     max_reads=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f165e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81458bde",
   "metadata": {},
   "source": [
    "# Run model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96766c8b",
   "metadata": {},
   "source": [
    "Model inference is perfomed using the `run_inference` function as described below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ea1dc4",
   "metadata": {},
   "source": [
    "### run_inference:\n",
    "**Required arguments**:\n",
    "- `data`: The first argument takes the preprocessed data which is the resulting output from the **parse** function.\n",
    "- `outpath`: The second argument takes a path to the directory to which the results of inference are to be saved.\n",
    "\n",
    "**Optional keyword arguments**:\n",
    "- `n_seeds`: This argument corresponds to how many resets are to be used for model inference. The model is then run `n_seeds` number of times and the best model is selected as the one with the lowest ELBO loss. The default value is 10.\n",
    "- `n_epochs`: This is the number of training epochs to use in each reset. Default value is 20000.\n",
    "- `learning_rate`: Learning rate to be used with the ADAM optimizer. Default  value is 5e-3.\n",
    "- `num_assemblages`: Maximum possible assemblages the model can learn. Default value is 100.\n",
    "- `sparsity_prior`: Prior probability of an assemblage being present. The default value is None, which sets the value to 0.5/`num_assemblages`.\n",
    "- `sparsity_power`: Power to which we raise the sparsity prior to scale with the dataset size. Default value is `None` which sets the value to 0.5% of the total number of reads in the dataset.\n",
    "- `anneal_prior`: Specifies whether to anneal the strength of the sparsity prior during training. Default value is True.\n",
    "- `process_variance_prior`: Prior location of the process variance prior. Default value is `0.01`.\n",
    "- `perturbation_prior`: Prior probability of a perturbation effect. Default value is None, which sets the value to 0.5/`num_assemblages`.\n",
    "- `use_contamination`: Whether to use the contamination cluster in the model. Default value is True.\n",
    "- `use_sparsity`: Specifies whether to sparsify the number of assemblages in the model. Default value is True.\n",
    "- `use_kmeans_init`: Specifies whether to use a kmeans initialization for assemblage parameters. Default value is True.\n",
    "- `device`: Specifies whether to use the CPU or GPU for model inference. By default, the software automatically detects and utilizes the GPU if available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b2a45e",
   "metadata": {},
   "source": [
    "For this tutorial, we will run the MCSPACE model with 1 seed and 5000 epochs, keeping other arguments at their default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3156fa08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 0...\n",
      "\n",
      "epoch 0\n",
      "ELBO =  tensor(19047444., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 100\n",
      "ELBO =  tensor(17319550., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 200\n",
      "ELBO =  tensor(24300204., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 300\n",
      "ELBO =  tensor(16783106., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 400\n",
      "ELBO =  tensor(19797684., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 500\n",
      "ELBO =  tensor(15433475., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 600\n",
      "ELBO =  tensor(16299382., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 700\n",
      "ELBO =  tensor(17427090., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 800\n",
      "ELBO =  tensor(20004712., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 900\n",
      "ELBO =  tensor(19617648., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 1000\n",
      "ELBO =  tensor(20832696., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 1100\n",
      "ELBO =  tensor(22068550., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 1200\n",
      "ELBO =  tensor(23292884., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 1300\n",
      "ELBO =  tensor(24209236., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 1400\n",
      "ELBO =  tensor(25243272., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 1500\n",
      "ELBO =  tensor(26435876., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 1600\n",
      "ELBO =  tensor(27612042., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 1700\n",
      "ELBO =  tensor(28476370., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 1800\n",
      "ELBO =  tensor(29366122., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 1900\n",
      "ELBO =  tensor(30354346., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 2000\n",
      "ELBO =  tensor(31282256., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 2100\n",
      "ELBO =  tensor(32192984., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 2200\n",
      "ELBO =  tensor(33093304., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 2300\n",
      "ELBO =  tensor(33954480., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 2400\n",
      "ELBO =  tensor(34821496., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 2500\n",
      "ELBO =  tensor(35653648., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 2600\n",
      "ELBO =  tensor(36445624., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 2700\n",
      "ELBO =  tensor(37147772., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 2800\n",
      "ELBO =  tensor(37889920., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 2900\n",
      "ELBO =  tensor(38647724., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 3000\n",
      "ELBO =  tensor(39273936., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 3100\n",
      "ELBO =  tensor(39968896., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 3200\n",
      "ELBO =  tensor(40696276., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 3300\n",
      "ELBO =  tensor(41397728., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 3400\n",
      "ELBO =  tensor(42083496., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 3500\n",
      "ELBO =  tensor(42717512., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 3600\n",
      "ELBO =  tensor(43375432., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 3700\n",
      "ELBO =  tensor(43998800., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 3800\n",
      "ELBO =  tensor(44640212., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 3900\n",
      "ELBO =  tensor(45266848., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 4000\n",
      "ELBO =  tensor(45847648., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 4100\n",
      "ELBO =  tensor(46411916., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 4200\n",
      "ELBO =  tensor(47020352., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 4300\n",
      "ELBO =  tensor(47633124., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 4400\n",
      "ELBO =  tensor(48297252., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 4500\n",
      "ELBO =  tensor(48889632., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 4600\n",
      "ELBO =  tensor(48487944., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 4700\n",
      "ELBO =  tensor(48063664., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 4800\n",
      "ELBO =  tensor(47613556., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 4900\n",
      "ELBO =  tensor(47134428., device='cuda:0', grad_fn=<NegBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gary\\documents\\projects\\mcspace_final\\mcspace\\mcspace\\utils.py:412: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(respath / MODEL_FILE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gary\\documents\\projects\\mcspace_final\\mcspace\\mcspace\\inference.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(respath / MODEL_FILE)\n"
     ]
    }
   ],
   "source": [
    "run_inference(processed_data,\n",
    "              outpath,\n",
    "              n_seeds=1,\n",
    "              n_epochs=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aa9102",
   "metadata": {},
   "source": [
    "# Results of model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd3c254",
   "metadata": {},
   "source": [
    "We output inference results in the folder `results/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d75e3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows-SSD\n",
      " Volume Serial Number is 1086-9223\n",
      "\n",
      " Directory of C:\\Users\\Gary\\Documents\\PROJECTS\\MCSPACE_FINAL\\MCSPACE\\mcspace\\tutorials\\results\n",
      "\n",
      "12/05/2024  01:01 PM    <DIR>          .\n",
      "12/05/2024  01:00 PM    <DIR>          ..\n",
      "12/05/2024  12:57 PM            21,737 assemblage_proportions.csv\n",
      "12/05/2024  12:57 PM            19,785 assemblages.csv\n",
      "12/04/2024  04:34 PM    <DIR>          best_model\n",
      "12/05/2024  09:00 AM     2,986,704,688 data.pkl\n",
      "12/05/2024  12:57 PM               612 perturbation_bayes_factors.csv\n",
      "12/05/2024  12:57 PM             2,078 relative_abundances.csv\n",
      "12/05/2024  12:57 PM            22,124 results.pkl\n",
      "12/04/2024  04:28 PM    <DIR>          runs\n",
      "               6 File(s)  2,986,771,024 bytes\n",
      "               4 Dir(s)  686,151,352,320 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls \"results/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1178cf",
   "metadata": {},
   "source": [
    "The folder contains the following results from inference:\n",
    "- `assemblages.csv`: A csv file containing the learned assemblages, with rows corresponding to each OTU and columns for each assemblages.\n",
    "- `assemblage_proportions.csv`: A csv file giving the posterior summary of inferred assemblage proportions, in long format, for each assemblage at each timepoint for each subject.\n",
    "- `perturbation_bayes_factors.csv`: A csv file containing the perturbation Bayes factors with columns corresponding to each perturbed timepoint and rows for each assemblage.\n",
    "- `runs`: Folder containing model inference results for each seed run. The `model.pt` file in each folder gives the saved pytorch model for each corresponding seed.\n",
    "- `best_model`: Folder containing inference results for the seed with the lowest average ELBO loss, and which is used to generate posterior summaries.\n",
    "- `results.pkl`: A pickle file containing posterior summaries of inferred parameters. This contains the same information as the csv files. This file can be used with our visulization functions for easy visualization of model results. See next tutorial `visualizating_results.ipynb` for more details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mcspace]",
   "language": "python",
   "name": "conda-env-mcspace-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
