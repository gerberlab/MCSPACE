{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aa2193e",
   "metadata": {},
   "source": [
    "# Tutorial 2: Running inference with the MCSPACE model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfb25d8",
   "metadata": {},
   "source": [
    "This tutorial goes over how to run model inference on processed SAMPL-seq data. Refer to the previous tutorial (`data_preprocessing.ipynb`) on how to prepare data for inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f49c0288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcspace.data_utils import parse\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from mcspace.utils import pickle_save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e11f758",
   "metadata": {},
   "source": [
    "The \"run_inference\" function performs model inference on preprocessed SAMPL-seq data. Import it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a5d75bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcspace.inference import run_inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379b5ea2",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4ce289",
   "metadata": {},
   "source": [
    "Relative paths for this tutorial. `basepath` gives the path of this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2020e645",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = Path(\"./\")\n",
    "datapath = basepath / \"data\"\n",
    "outpath = basepath / \"results\"\n",
    "outpath.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f7063f",
   "metadata": {},
   "source": [
    "# Process data for model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e885b4bf",
   "metadata": {},
   "source": [
    "See previous tutorial `data_preprocessing.ipynb` for more details on this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a0edbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_remove = [10,18,65,76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd5d10c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gary\\documents\\projects\\mcspace_revisions_8_29_25\\mcspace\\mcspace\\dataset.py:23: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self._long_data = pd.read_csv(reads, compression='gzip')\n"
     ]
    }
   ],
   "source": [
    "processed_data = parse(datapath/\"mouse_counts.csv.gz\",\n",
    "                     datapath/\"taxonomy.csv\",\n",
    "                     datapath/\"perturbations.csv\",\n",
    "                     subjects_remove=['JX09'],\n",
    "                     times_remove=times_remove,\n",
    "                     otus_remove=None,\n",
    "                     num_consistent_subjects=2,\n",
    "                     min_abundance=0.005,\n",
    "                     min_reads=1000,\n",
    "                     max_reads=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f165e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81458bde",
   "metadata": {},
   "source": [
    "# Run model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96766c8b",
   "metadata": {},
   "source": [
    "Model inference is perfomed using the `run_inference` function as described below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ea1dc4",
   "metadata": {},
   "source": [
    "### run_inference:\n",
    "**Required arguments**:\n",
    "- `data`: The first argument takes the preprocessed data which is the resulting output from the **parse** function.\n",
    "- `outpath`: The second argument takes a path to the directory to which the results of inference are to be saved.\n",
    "\n",
    "**Optional keyword arguments**:\n",
    "- `n_seeds`: This argument corresponds to how many resets are to be used for model inference. The model is then run `n_seeds` number of times and the best model is selected as the one with the lowest ELBO loss. The default value is 10.\n",
    "- `n_epochs`: This is the number of training epochs to use in each reset. Default value is 20000.\n",
    "- `learning_rate`: Learning rate to be used with the ADAM optimizer. Default  value is 5e-3.\n",
    "- `num_assemblages`: Maximum possible assemblages the model can learn. Default value is 100.\n",
    "- `sparsity_prior`: Prior probability of an assemblage being present. The default value is None, which sets the value to 0.5/`num_assemblages`.\n",
    "- `sparsity_power`: Power to which we raise the sparsity prior to scale with the dataset size. Default value is `None` which sets the value to 0.5% of the total number of reads in the dataset.\n",
    "- `anneal_prior`: Specifies whether to anneal the strength of the sparsity prior during training. Default value is True.\n",
    "- `process_variance_prior`: Prior location of the process variance prior. Default value is `0.01`.\n",
    "- `perturbation_prior`: Prior probability of a perturbation effect. Default value is None, which sets the value to 0.5/`num_assemblages`.\n",
    "- `use_contamination`: Whether to use the contamination cluster in the model. Default value is True.\n",
    "- `use_sparsity`: Specifies whether to sparsify the number of assemblages in the model. Default value is True.\n",
    "- `use_kmeans_init`: Specifies whether to use a kmeans initialization for assemblage parameters. Default value is True.\n",
    "- `device`: Specifies whether to use the CPU or GPU for model inference. By default, the software automatically detects and utilizes the GPU if available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b2a45e",
   "metadata": {},
   "source": [
    "For this tutorial, we will run the MCSPACE model with 1 seed and 5000 epochs, keeping other arguments at their default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3156fa08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 0...\n",
      "\n",
      "epoch 0\n",
      "ELBO =  tensor(19047362., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 100\n",
      "ELBO =  tensor(17319594., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 200\n",
      "ELBO =  tensor(24300228., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 300\n",
      "ELBO =  tensor(16783074., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 400\n",
      "ELBO =  tensor(19798072., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 500\n",
      "ELBO =  tensor(15433439., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 600\n",
      "ELBO =  tensor(16299690., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 700\n",
      "ELBO =  tensor(17427712., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 800\n",
      "ELBO =  tensor(20006550., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 900\n",
      "ELBO =  tensor(19618514., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 1000\n",
      "ELBO =  tensor(20832796., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 1100\n",
      "ELBO =  tensor(22068986., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 1200\n",
      "ELBO =  tensor(23293548., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 1300\n",
      "ELBO =  tensor(24210548., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 1400\n",
      "ELBO =  tensor(25242744., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 1500\n",
      "ELBO =  tensor(26438244., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 1600\n",
      "ELBO =  tensor(27615472., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 1700\n",
      "ELBO =  tensor(28478256., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 1800\n",
      "ELBO =  tensor(29368954., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 1900\n",
      "ELBO =  tensor(30356076., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 2000\n",
      "ELBO =  tensor(31273748., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 2100\n",
      "ELBO =  tensor(32182200., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 2200\n",
      "ELBO =  tensor(33078308., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 2300\n",
      "ELBO =  tensor(33937420., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 2400\n",
      "ELBO =  tensor(34797540., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 2500\n",
      "ELBO =  tensor(35625540., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 2600\n",
      "ELBO =  tensor(36410552., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 2700\n",
      "ELBO =  tensor(37119184., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 2800\n",
      "ELBO =  tensor(37855852., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 2900\n",
      "ELBO =  tensor(38635104., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 3000\n",
      "ELBO =  tensor(39267188., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 3100\n",
      "ELBO =  tensor(39939600., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 3200\n",
      "ELBO =  tensor(40660912., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 3300\n",
      "ELBO =  tensor(41361984., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 3400\n",
      "ELBO =  tensor(42031444., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 3500\n",
      "ELBO =  tensor(42695376., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 3600\n",
      "ELBO =  tensor(43354156., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 3700\n",
      "ELBO =  tensor(43980120., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 3800\n",
      "ELBO =  tensor(44643524., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 3900\n",
      "ELBO =  tensor(45286608., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 4000\n",
      "ELBO =  tensor(45900392., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 4100\n",
      "ELBO =  tensor(46466368., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 4200\n",
      "ELBO =  tensor(47056036., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 4300\n",
      "ELBO =  tensor(47614028., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 4400\n",
      "ELBO =  tensor(48355708., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 4500\n",
      "ELBO =  tensor(48953260., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 4600\n",
      "ELBO =  tensor(48540112., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 4700\n",
      "ELBO =  tensor(48102624., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 4800\n",
      "ELBO =  tensor(47644604., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "epoch 4900\n",
      "ELBO =  tensor(47159208., device='cuda:0', grad_fn=<NegBackward0>)\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "run_inference(processed_data,\n",
    "              outpath,\n",
    "              n_seeds=1,\n",
    "              n_epochs=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aa9102",
   "metadata": {},
   "source": [
    "# Results of model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd3c254",
   "metadata": {},
   "source": [
    "We output inference results in the folder `results/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d75e3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows-SSD\n",
      " Volume Serial Number is 1086-9223\n",
      "\n",
      " Directory of c:\\Users\\Gary\\Documents\\PROJECTS\\MCSPACE_revisions_8_29_25\\MCSPACE\\mcspace\\tutorials\\results\n",
      "\n",
      "08/29/2025  03:02 PM    <DIR>          .\n",
      "08/29/2025  02:59 PM    <DIR>          ..\n",
      "08/29/2025  03:02 PM            20,690 assemblage_proportions.csv\n",
      "08/29/2025  03:02 PM            18,970 assemblages.csv\n",
      "08/29/2025  03:02 PM    <DIR>          best_model\n",
      "08/29/2025  03:02 PM               581 perturbation_bayes_factors.csv\n",
      "08/29/2025  03:02 PM             2,078 relative_abundances.csv\n",
      "08/29/2025  03:02 PM            21,294 results.pkl\n",
      "08/29/2025  02:59 PM    <DIR>          runs\n",
      "               5 File(s)         63,613 bytes\n",
      "               4 Dir(s)  365,254,557,696 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls \"results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c05eeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows-SSD\n",
      " Volume Serial Number is 1086-9223\n",
      "\n",
      " Directory of c:\\Users\\Gary\\Documents\\PROJECTS\\MCSPACE_revisions_8_29_25\\MCSPACE\\mcspace\\tutorials\\results\\runs\\seed_0\n",
      "\n",
      "08/29/2025  03:02 PM    <DIR>          .\n",
      "08/29/2025  02:59 PM    <DIR>          ..\n",
      "08/29/2025  03:02 PM         2,667,946 data.pkl\n",
      "08/29/2025  03:02 PM            40,151 elbos.pkl\n",
      "08/29/2025  03:02 PM           308,399 model.pt\n",
      "08/29/2025  03:02 PM             2,394 taxonomy.pkl\n",
      "               4 File(s)      3,018,890 bytes\n",
      "               2 Dir(s)  365,259,993,088 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls \"results/runs/seed_0/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1178cf",
   "metadata": {},
   "source": [
    "The folder contains the following results from inference:\n",
    "- `assemblages.csv`: A csv file containing the learned assemblages, with rows corresponding to each OTU and columns for each assemblages.\n",
    "- `assemblage_proportions.csv`: A csv file giving the posterior summary of inferred assemblage proportions, in long format, for each assemblage at each timepoint for each subject.\n",
    "- `perturbation_bayes_factors.csv`: A csv file containing the perturbation Bayes factors with columns corresponding to each perturbed timepoint and rows for each assemblage.\n",
    "- `runs`: Folder containing model inference results for each seed run. The `model.pt` file in each folder gives the saved pytorch model for each corresponding seed. The `elbos.pkl` file gives the ELBO loss at each epoch for the run to help users monitor and assess model convergence and training quality.\n",
    "- `best_model`: Folder containing inference results for the seed with the lowest average ELBO loss, and which is used to generate posterior summaries.\n",
    "- `results.pkl`: A pickle file containing posterior summaries of inferred parameters. This contains the same information as the csv files. This file can be used with our visulization functions for easy visualization of model results. See next tutorial `visualizating_results.ipynb` for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25258a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcrev-clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
